# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: нелинейная структура, выбросы, лишний шумовой признак

### 1.2 Dataset B

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности и фоновый шум

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (10000, 33)
- Признаки: числовые и два категориальных
- Пропуски: есть, во всех признаках кроме категориальных, ~2% от всех данных в признаке
- "Подлости" датасета: высокая размерность, 2 категориальных признака и пропуски в числовых

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: scaling, imputation
- Поиск гиперпараметров:
  - Для KMeans диапазон k от 2 до 20, для DBSCAN - min_samples в диапазоне [40, 45, 50, 55, 60, 65]
  - чем руководствовались при выборе "лучшего" - сравнение метрик
- Метрики: silhouette, Davies-Bouldin, Calinski-Harabasz. Для DBSCAN при наличии шума сначала отбрасывались шумовые значения.
- Визуализация: PCA(2D)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Dataset A:

- KMeans (поиск `k`, фиксировали `random_state`=19, `n_init`=10)
- DBSCAN (`eps` = 0.30, `min_samples` = 50, доля шума - 0.22025)

Dataset B:

- KMeans (поиск `k`, фиксировали `random_state`=19, `n_init`=10)
- DBSCAN (`eps` = 0.50, `min_samples` = 8, доля шума - 0.029333333333333333)

Dataset C:

- KMeans (поиск `k`, фиксировали `random_state`=19, `n_init`=10)
- DBSCAN (`eps` = 3.50, `min_samples` = 60, доля шума - 0)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с k=2
- Метрики (silhouette / DB / CH):
        silhouette_score: 0.3068599193274176
        davies_bouldin_score: 1.3234715790226015
        calinski_harabasz_score: 3573.397151201895
- Если был DBSCAN: доля шума и комментарий:
        Доля шума 0.22025 - слишком много
- Коротко: почему это решение выглядит разумным именно для этого датасета
        Решение выглядит разумным исходя из метрик, превышающих метрики DBSCAN для этого же датасета, а также из слишком высокой доли шума в подобранном "наилучшем" варианте DBSCAN.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans с k=3
- Метрики (silhouette / DB / CH):
        silhouette_score: 0.28171083465950286
        davies_bouldin_score: 1.2918988354260355
        calinski_harabasz_score: 5922.387285284038
- Если был DBSCAN: доля шума и комментарий:
        Доля шума 0.0293 - разумно
- Коротко: почему это решение выглядит разумным именно для этого датасета
        Решение выглядит разумным исходя из метрик, превышающих метрики DBSCAN для этого же датасета.

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN с eps=3.50, min_samples=60
- Метрики (silhouette / DB / CH):
        silhouette_score: 0.4548642894346598
        davies_bouldin_score: 0.9523106734585932
        calinski_harabasz_score: 5323.500116564788
- Если был DBSCAN: доля шума и комментарий:
        Доля шума 0 - идеально
- Коротко: почему это решение выглядит разумным именно для этого датасета
        Решение выглядит разумным исходя из метрик, превышающих метрики KMeans для этого же датасета.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему?
KMeans — мощный, но простой алгоритм с жесткими предположениями. Он "ломается" в следующих сценариях:
а) Кластеры не сферические / невыпуклые, так как KMeans минимизирует сумму квадратов расстояний до центроидов, что по сути предполагает, что кластеры являются сферическими (как шары) и одинакового размера.
б) Наличие шума и выбросов, так как выброс сильно влияет на положение центроида, "притягивая" его к себе. Это искажает весь процесс кластеризации. Выброс также может быть ошибочно выделен в отдельный кластер, если значение k задано с запасом.
в) Кластеры разной плотности и размера, так как алгоритм стремится сделать кластеры примерно равного размера (по числу точек) и радиуса, так как оптимизирует единую метрику (инерцию). Большой разреженный кластер может быть "разрезан" в пользу маленького плотного.

- Где DBSCAN/иерархическая кластеризация выигрывают и почему?
Они выигрывают именно там, где KMeans "ломается", потому что основаны на других идеях. DBSCAN (Density-Based Spatial Clustering) выигрывает, когда: неизвестно число кластеров (k) - алгоритм находит его сам; кластеры произвольной формы - ищет области высокой плотности, разделенные областями низкой плотности; в данных есть шум/выбросы - точки в областях низкой плотности помечаются как шум (-1) и не портят кластеры.

- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
Сильнее всего на результат влияло масштабирование, выбросы (для KMeans), категориальные признаки и пропуски.

### 5.2 Устойчивость (обязательно для одного датасета)

- Для проверки устойчивости выполнено 5 запусков KMeans по разным seed
- Результаты модели не изменились при разном seed
- Решение устойчиво, так ка результаты не менялись

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - средние значения признаков
- Выбор алгоритма зависит от размерности данных и наличия шума. KMeans подходит для большинства случаев, DBSCAN - для данных с аномалиями, но требует тщательной настройки параметров.

## 6. Conclusion

Ключевая проблема без разметки - оценка качества кластеризации объективна только через экспертизу или косвенные метрики, так как истинных «правильных» кластеров не существует. Предобработка и масштабирование - часто критичнее выбора алгоритма. Алгоритм зависит от задачи: k-means ищет сферические кластеры, DBSCAN — плотностные и выбросы. Визуализация помогает оценить осмысленность кластеров в сниженной размерности.