# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-03.csv`
- Размер: (15000, 30)
- Целевая переменная: `target` (0    0.542533
                                1    0.302333
                                2    0.155133)
- Признаки: числовые типы (float64)

## 2. Protocol

- Разбиение: train/test (`test_size` = 0.2, `random_state` = 19)
- Подбор: CV на train (5 фолдов, оптимизировали f1_macro)
- Метрики: accuracy, F1_macro, multi-class AUC (OVR)  (поскольку датасет мультиклассовый)

## 3. Models

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf`)
- RandomForestClassifier ()
- AdaBoost
- StackingClassifier (3 базовых модели LogisticRegression, RandomForestClassifier, GradientBoostingClassifier + метамодель LogisticRegression)

## 4. Results

- Cписок финальных метрик на test по всем моделям

{
  "LogisticRegression": {
    "accuracy": 0.722,
    "f1": 0.659966031037906,
    "roc_auc": 0.8427919367389375
  },
  "DummyClassier": {
    "accuracy": 0.415,
    "f1": 0.3467754141975747,
    "roc_auc": 0.4986592360739018
  },
  "DecisionTreeClassifier": {
    "accuracy": 0.7786666666666666,
    "f1": 0.7290730341838492,
    "roc_auc": 0.8418148152169138
  },
  "RandomForestClassifier": {
    "accuracy": 0.884,
    "f1": 0.8584655173602185,
    "roc_auc": 0.9496376877918012
  },
  "AdaBoostClassifier": {
    "accuracy": 0.7023333333333334,
    "f1": 0.6274674336438543,
    "roc_auc": 0.8332641704298753
  },
  "StackingClassifier": {
    "accuracy": 0.9033333333333333,
    "f1": 0.8821019435570325,
    "roc_auc": 0.9569778771887719
  }
}
  
- Победитель (по согласованному критерию f1_macro) и краткое объяснение:

StackingClassifier, f1_macro = 0.8821019435570325

## 5. Analysis

- Устойчивость: в результате обучения и оценки нескольких моделей DecisionTreeClassifier с разным `random_state` наблюдаем, что метрики не меняются с изменением `random_state` - модель устойчива. 
- Ошибки: После анализа confusion matrix, полученной по результатам оценки модели StackingClassifier (как наилучшего результата), видим. что основная концентрация ответов модели находится на главной диагонали матрицы, что свидетельствует о высоком проценте корректных предсказаний.
- Интерпретация: Наибольшим влиянием обладает признак f13, значительно обходя предыдущий f05 (~0.025 accuracy drop), который, в свою очередь, по влиянию также значительно превышает f28 (~0.04 accuracy drop). Последующие признаки уже не имеют между собой столь значительных различий по влиянию на результат модели. Вывод - модель сильно зависит от небольшого числа ключевых признаков (f13, f05, f28), причем признак f13 является критически важным.

## 6. Conclusion

Одиночное дерево легко интерпретировать, но ансамбли (случайный лес, градиентный бустинг) жертвуют наглядностью ради значительного роста точности и устойчивости.  Основная сила ансамблей - в комбинировании множества слабых моделей для уменьшения дисперсии (бэггинг) или смещения (бустинг). Деревья и их ансамбли не требуют масштабирования данных, устойчивы к выбросам и могут работать с разнотипными признаками. Одиночное дерево склонно к сильному переобучению; ансамбли борются с этим через рандомизацию и усреднение, но бустинг при недостаточном контроле также может переобучаться. Ключевой принцип честного ML-протокола - непересекающиеся выборки для обучения, настройки гиперпараметров и финального тестирования. Утечка информации между этапами ведет к необъективной оценке.